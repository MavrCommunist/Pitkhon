[{
  "_id": "1601.07929",
  "title": "Probabilistic Models for Computerized Adaptive Testing: Experiments\n",
  "authors": "Martin Plajner, Jiří Vomlel",
  "subject": "Artificial Intelligence (cs.AI)",
  "annotation": " This paper follows previous research we have already performed in the area of\nBayesian networks models for CAT. We present models using Item Response Theory\n(IRT - standard CAT method), Bayesian networks, and neural networks. We\nconducted simulated CAT tests on empirical data. Results of these tests are\npresented for each model separately and compared.\n"
},{
  "_id": "1601.07883",
  "title": "Towards the Design of an End-to-End Automated System for Image and  Video-based Recognition\n",
  "authors": "Rama Chellappa, Jun-Cheng Chen, Rajeev Ranjan, Swami Sankaranarayanan, Amit Kumar, Vishal M. Patel, Carlos D. Castillo",
  "subject": "Computer Vision and Pattern Recognition (cs.CV)",
  "annotation": " Over many decades, researchers working in object recognition have longed for\nan end-to-end automated system that will simply accept 2D or 3D image or videos\nas inputs and output the labels of objects in the input data. Computer vision\nmethods that use representations derived based on geometric, radiometric and\nneural considerations and statistical and structural matchers and artificial\nneural network-based methods where a multi-layer network learns the mapping\nfrom inputs to class labels have provided competing approaches for image\nrecognition problems. Over the last four years, methods based on Deep\nConvolutional Neural Networks (DCNNs) have shown impressive performance\nimprovements on object detection/recognition challenge problems. This has been\nmade possible due to the availability of large annotated data, a better\nunderstanding of the non-linear mapping between image and class labels as well\nas the affordability of GPUs. In this paper, we present a brief history of\ndevelopments in computer vision and artificial neural networks over the last\nforty years for the problem of image-based recognition. We then present the\ndesign details of a deep learning system for end-to-end unconstrained face\nverification/recognition. Some open issues regarding DCNNs for object\nrecognition problems are then discussed. We caution the readers that the views\nexpressed in this paper are from the authors and authors only!\n"
},{
  "_id": "1601.06071",
  "title": "Bitwise Neural Networks\n",
  "authors": "Minje Kim, Paris Smaragdis",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " Based on the assumption that there exists a neural network that efficiently\nrepresents a set of Boolean functions between all binary inputs and outputs, we\npropose a process for developing and deploying neural networks whose weight\nparameters, bias terms, input, and intermediate hidden layer output signals,\nare all binary-valued, and require only basic bit logic for the feedforward\npass. The proposed Bitwise Neural Network (BNN) is especially suitable for\nresource-constrained environments, since it replaces either floating or\nfixed-point arithmetic with significantly more efficient bitwise operations.\nHence, the BNN requires for less spatial complexity, less memory bandwidth, and\nless power consumption in hardware. In order to design such networks, we\npropose to add a few training schemes, such as weight compression and noisy\nbackpropagation, which result in a bitwise network that performs almost as well\nas its corresponding real-valued network. We test the proposed network on the\nMNIST dataset, represented using binary features, and show that BNNs result in\ncompetitive performance while offering dramatic computational savings.\n"
},{
  "_id": "1601.06008",
  "title": "A Robust Frame-based Nonlinear Prediction System for Automatic Speech  Coding\n",
  "authors": "Mahmood Yousefi-Azar, Farbod Razzazi",
  "subject": "Sound (cs.SD)",
  "annotation": " In this paper, we propose a neural-based coding scheme in which an artificial\nneural network is exploited to automatically compress and decompress speech\nsignals by a trainable approach. Having a two-stage training phase, the system\ncan be fully specified to each speech frame and have robust performance across\ndifferent speakers and wide range of spoken utterances. Indeed, Frame-based\nnonlinear predictive coding (FNPC) would code a frame in the procedure of\ntraining to predict the frame samples. The motivating objective is to analyze\nthe system behavior in regenerating not only the envelope of spectra, but also\nthe spectra phase. This scheme has been evaluated in time and discrete cosine\ntransform (DCT) domains and the output of predicted phonemes show the\npotentiality of the FNPC to reconstruct complicated signals. The experiments\nwere conducted on three voiced plosive phonemes, b/d/g/ in time and DCT domains\nversus the number of neurons in the hidden layer. Experiments approve the FNPC\ncapability as an automatic coding system by which /b/d/g/ phonemes have been\nreproduced with a good accuracy. Evaluations revealed that the performance of\nFNPC system, trained to predict DCT coefficients is more desirable,\nparticularly for frames with the wider distribution of energy, compared to time\nsamples.\n"
},{
  "_id": "1601.04248",
  "title": "Word Existence Algorithm\n",
  "authors": "Tejeswini Sundaram, Vyom Chabbra",
  "subject": "Data Structures and Algorithms (cs.DS)",
  "annotation": " The current scenario in the field of computing is largely affected by the\nspeed at which data can be accessed and recalled. In this paper, we present the\nword existence algorithm which is used to check if the word given as an input\nis part of a particular database or not. We have taken the English language as\nan example here. This algorithm tries to solve the problem of lookup by using a\nuniformly distributed hash function. We have also addressed the problem of\nclustering and collision. A further contribution is that we follow a direct\nhashed model where each hash value is linked to another table if the continuity\nfor the function holds true. The core of the algorithm lies in the data model\nbeing used during preordering. Our focus lies on the formation of a continuity\nseries and validating the words that exists in the database. This algorithm can\nbe used in applications where we there is a requirement to search for just the\nexistence of a word, example Artificial Intelligence responding to input ,look\nup for neural networks and dictionary lookups and more. We have observed that\nthis algorithm provides a faster search time\n"
},{
  "_id": "1601.04187",
  "title": "Conversion of Artificial Recurrent Neural Networks to Spiking Neural  Networks for Low-power Neuromorphic Hardware\n",
  "authors": "Peter U. Diehl, Guido Zarrella, Andrew Cassidy, Bruno U. Pedroni, Emre Neftci",
  "subject": "Neural and Evolutionary Computing (cs.NE)",
  "annotation": " In recent years the field of neuromorphic low-power systems that consume\norders of magnitude less power gained significant momentum. However, their\nwider use is still hindered by the lack of algorithms that can harness the\nstrengths of such architectures. While neuromorphic adaptations of\nrepresentation learning algorithms are now emerging, efficient processing of\ntemporal sequences or variable length-inputs remain difficult. Recurrent neural\nnetworks (RNN) are widely used in machine learning to solve a variety of\nsequence learning tasks. In this work we present a train-and-constrain\nmethodology that enables the mapping of machine learned (Elman) RNNs on a\nsubstrate of spiking neurons, while being compatible with the capabilities of\ncurrent and near-future neuromorphic systems. This \"train-and-constrain\" method\nconsists of first training RNNs using backpropagation through time, then\ndiscretizing the weights and finally converting them to spiking RNNs by\nmatching the responses of artificial neurons with those of the spiking neurons.\nWe demonstrate our approach by mapping a natural language processing task\n(question classification), where we demonstrate the entire mapping process of\nthe recurrent layer of the network on IBM's Neurosynaptic System \"TrueNorth\", a\nspike-based digital neuromorphic hardware architecture. TrueNorth imposes\nspecific constraints on connectivity, neural and synaptic parameters. To\nsatisfy these constraints, it was necessary to discretize the synaptic weights\nand neural activities to 16 levels, and to limit fan-in to 64 inputs. We find\nthat short synaptic delays are sufficient to implement the dynamical (temporal)\naspect of the RNN in the question classification task. The hardware-constrained\nmodel achieved 74% accuracy in question classification while using less than\n0.025% of the cores on one TrueNorth chip, resulting in an estimated power\nconsumption of ~17 uW.\n"
},{
  "_id": "1601.03809",
  "title": "Artificial neural network approach for condition-based maintenance\n",
  "authors": "Mostafa Sayyed",
  "subject": "Neural and Evolutionary Computing (cs.NE)",
  "annotation": " In this research, computerized maintenance management will be investigated.\nThe rise of maintenance cost forced the research community to look for more\neffective ways to schedule maintenance operations. Using computerized models to\ncome up with optimal maintenance policy has led to better equipment utilization\nand lower costs. This research adopts Condition-Based Maintenance model where\nthe maintenance decision is generated based on equipment conditions. Artificial\nNeural Network technique is proposed to capture and analyze equipment condition\nsignals which lead to higher level of knowledge gathering. This knowledge is\nused to accurately estimate equipment failure time. Based on these estimations,\nan optimal maintenance management policy can be achieved.\n"
},{
  "_id": "1601.03349",
  "title": "The star formation rates of active galactic nuclei host galaxies\n",
  "authors": "Sara L. Ellison, Hossen Teimoorinia, David J. Rosario, J. Trevor Mendel",
  "subject": "Astrophysics of Galaxies (astro-ph.GA)",
  "annotation": " Using artificial neural network (ANN) predictions of total infra-red\nluminosities (LIR), we compare the host galaxy star formation rates (SFRs) of\n~21,000 optically selected active galactic nuclei (AGN), 466 low excitation\nradio galaxies (LERGs) and 721 mid-IR selected AGN. SFR offsets (Delta SFR)\nrelative to a sample of star-forming `main sequence' galaxies (matched in M*, z\nand local environment) are computed for the AGN hosts. Optically selected AGN\nexhibit a wide range of Delta SFR, with a distribution skewed to low SFRs and a\nmedian Delta SFR = -0.06 dex. The LERGs have SFRs that are shifted to even\nlower values with a median Delta SFR = -0.5 dex. In contrast, mid-IR selected\nAGN have, on average, SFRs enhanced by a factor ~1.5. We interpret the\ndifferent distributions of Delta SFR amongst the different AGN classes in the\ncontext of the relative contribution of triggering by galaxy mergers. Whereas\nthe LERGs are predominantly fuelled through low accretion rate secular\nprocesses which are not accompanied by enhancements in SFR, mergers, which can\nsimultaneously boost SFRs, most frequently lead to powerful, obscured AGN.\n"
},{
  "_id": "1601.03277",
  "title": "Weightless neural network parameters and architecture selection in a  quantum computer\n",
  "authors": "Adenilton J. da Silva, Wilson R. de Oliveira, Teresa B. Ludermir",
  "subject": "Quantum Physics (quant-ph)",
  "annotation": " Training artificial neural networks requires a tedious empirical evaluation\nto determine a suitable neural network architecture. To avoid this empirical\nprocess several techniques have been proposed to automatise the architecture\nselection process. In this paper, we propose a method to perform parameter and\narchitecture selection for a quantum weightless neural network (qWNN). The\narchitecture selection is performed through the learning procedure of a qWNN\nwith a learning algorithm that uses the principle of quantum superposition and\na non-linear quantum operator. The main advantage of the proposed method is\nthat it performs a global search in the space of qWNN architecture and\nparameters rather than a local search.\n"
},{
  "_id": "1601.03073",
  "title": "Infomax strategies for an optimal balance between exploration and  exploitation\n",
  "authors": "Gautam Reddy, Antonio Celani, Massimo Vergassola",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " Proper balance between exploitation and exploration is what makes good\ndecisions, which achieve high rewards like payoff or evolutionary fitness. The\nInfomax principle postulates that maximization of information directs the\nfunction of diverse systems, from living systems to artificial neural networks.\nWhile specific applications are successful, the validity of information as a\nproxy for reward remains unclear. Here, we consider the multi-armed bandit\ndecision problem, which features arms (slot-machines) of unknown probabilities\nof success and a player trying to maximize cumulative payoff by choosing the\nsequence of arms to play. We show that an Infomax strategy (Info-p) which\noptimally gathers information on the highest mean reward among the arms\nsaturates known optimal bounds and compares favorably to existing policies. The\nhighest mean reward considered by Info-p is not the quantity actually needed\nfor the choice of the arm to play, yet it allows for optimal tradeoffs between\nexploration and exploitation.\n"
},{
  "_id": "1601.02970",
  "title": "Deep Neural Networks predict Hierarchical Spatio-temporal Cortical  Dynamics of Human Visual Object Recognition\n",
  "authors": "Radoslaw M. Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio Torralba, Aude Oliva",
  "subject": "Computer Vision and Pattern Recognition (cs.CV)",
  "annotation": " The complex multi-stage architecture of cortical visual pathways provides the\nneural basis for efficient visual object recognition in humans. However, the\nstage-wise computations therein remain poorly understood. Here, we compared\ntemporal (magnetoencephalography) and spatial (functional MRI) visual brain\nrepresentations with representations in an artificial deep neural network (DNN)\ntuned to the statistics of real-world visual recognition. We showed that the\nDNN captured the stages of human visual processing in both time and space from\nearly visual areas towards the dorsal and ventral streams. Further\ninvestigation of crucial DNN parameters revealed that while model architecture\nwas important, training on real-world categorization was necessary to enforce\nspatio-temporal hierarchical relationships with the brain. Together our results\nprovide an algorithmically informed view on the spatio-temporal dynamics of\nvisual object recognition in the human visual brain.\n"
},{
  "_id": "1601.02705",
  "title": "Robobarista: Learning to Manipulate Novel Objects via Deep Multimodal  Embedding\n",
  "authors": "Jaeyong Sung, Seok Hyun Jin, Ian Lenz, Ashutosh Saxena",
  "subject": "Robotics (cs.RO)",
  "annotation": " There is a large variety of objects and appliances in human environments,\nsuch as stoves, coffee dispensers, juice extractors, and so on. It is\nchallenging for a roboticist to program a robot for each of these object types\nand for each of their instantiations. In this work, we present a novel approach\nto manipulation planning based on the idea that many household objects share\nsimilarly-operated object parts. We formulate the manipulation planning as a\nstructured prediction problem and learn to transfer manipulation strategy\nacross different objects by embedding point-cloud, natural language, and\nmanipulation trajectory data into a shared embedding space using a deep neural\nnetwork. In order to learn semantically meaningful spaces throughout our\nnetwork, we introduce a method for pre-training its lower layers for multimodal\nfeature embedding and a method for fine-tuning this embedding space using a\nloss-based margin. In order to collect a large number of manipulation\ndemonstrations for different objects, we develop a new crowd-sourcing platform\ncalled Robobarista. We test our model on our dataset consisting of 116 objects\nand appliances with 249 parts along with 250 language instructions, for which\nthere are 1225 crowd-sourced manipulation demonstrations. We further show that\nour robot with our model can even prepare a cup of a latte with appliances it\nhas never seen before.\n"
},{
  "_id": "1601.01885",
  "title": "Visual Script and Language Identification\n",
  "authors": "Anguelos Nicolaou, Andrew Bagdanov, Lluis Gomez-Bigorda, Dimosthenis Karatzas",
  "subject": "Computer Vision and Pattern Recognition (cs.CV)",
  "annotation": " In this paper we introduce a script identification method based on\nhand-crafted texture features and an artificial neural network. The proposed\npipeline achieves near state-of-the-art performance for script identification\nof video-text and state-of-the-art performance on visual language\nidentification of handwritten text. More than using the deep network as a\nclassifier, the use of its intermediary activations as a learned metric\ndemonstrates remarkable results and allows the use of discriminative models on\nunknown classes. Comparative experiments in video-text and text in the wild\ndatasets provide insights on the internals of the proposed deep network.\n"
},{
  "_id": "1601.01258",
  "title": "An Artificial Neural Network Approach For Ranking Quenching Parameters  In Central Galaxies\n",
  "authors": "Hossen Teimoorinia, Asa F. L. Bluck, Sara L. Ellison",
  "subject": "Astrophysics of Galaxies (astro-ph.GA)",
  "annotation": " We present a novel technique for ranking the relative importance of galaxy\nproperties in the process of quenching star formation. Specifically, we develop\nan artificial neural network (ANN) approach for pattern recognition and apply\nit to a population of over 400,000 central galaxies taken from the Sloan\nDigital Sky Survey Data Release 7. We utilise a variety of physical galaxy\nproperties for training the pattern recognition algorithm to recognise star\nforming and passive systems, for a `training set' of $\\sim$100,000 galaxies. We\nthen apply the ANN model to a `verification set' of $\\sim$100,000 different\ngalaxies, randomly chosen from the remaining sample. The success rate of each\nparameter singly, and in conjunction with other parameters, is taken as an\nindication of how important the parameters are to the process(es) of central\ngalaxy quenching. We find that central velocity dispersion, bulge mass and B/T\nare excellent predictors of the passive state of the system, indicating that\nproperties related to the central mass of the galaxy are most closely linked to\nthe cessation of star formation. Larger scale galaxy properties (total or disk\nstellar masses), or those linked to environment (halo masses or $\\delta_5$)\nperform significantly less well. Our results are plausibly explained by AGN\nfeedback driving the quenching of central galaxies, although we discuss other\npossibilities as well.\n"
},{
  "_id": "1601.01157",
  "title": "A simple technique for improving multi-class classification with neural  networks\n",
  "authors": "Thomas Kopinski, Alexander Gepperth, Uwe Handmann",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " We present a novel method to perform multi-class pattern classification with\nneural networks and test it on a challenging 3D hand gesture recognition\nproblem. Our method consists of a standard one-against-all (OAA)\nclassification, followed by another network layer classifying the resulting\nclass scores, possibly augmented by the original raw input vector. This allows\nthe network to disambiguate hard-to-separate classes as the distribution of\nclass scores carries considerable information as well, and is in fact often\nused for assessing the confidence of a decision. We show that by this approach\nwe are able to significantly boost our results, overall as well as for\nparticular difficult cases, on the hard 10-class gesture classification task.\n"
},{
  "_id": "1601.01121",
  "title": "A pragmatic approach to multi-class classification\n",
  "authors": "Thomas Kopinski, Stéphane Magand, Uwe Handmann, Alexander Gepperth",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " We present a novel hierarchical approach to multi-class classification which\nis generic in that it can be applied to different classification models (e.g.,\nsupport vector machines, perceptrons), and makes no explicit assumptions about\nthe probabilistic structure of the problem as it is usually done in multi-class\nclassification. By adding a cascade of additional classifiers, each of which\nreceives the previous classifier's output in addition to regular input data,\nthe approach harnesses unused information that manifests itself in the form of,\ne.g., correlations between predicted classes. Using multilayer perceptrons as a\nclassification model, we demonstrate the validity of this approach by testing\nit on a complex ten-class 3D gesture recognition task.\n"
},{
  "_id": "1601.00917",
  "title": "DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing  Hyperparameters of Deep Neural Networks\n",
  "authors": "Jie Fu, Hongyin Luo, Jiashi Feng, Kian Hsiang Low, Tat-Seng Chua",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " The performance of deep neural networks is well-known to be sensitive to the\nsetting of their hyperparameters. Recent advances in reverse-mode automatic\ndifferentiation allow for optimizing hyperparameters with gradients. The\nstandard way of computing these gradients involves a forward and backward pass\nof computations. However, the backward pass usually needs to consume\nunaffordable memory to store all the intermediate variables to exactly reverse\nthe forward training procedure. In this work we propose a simple but effective\nmethod, DrMAD, to distill the knowledge of the forward pass into a shortcut\npath, through which we approximately reverse the training trajectory.\nExperiments on several image benchmark datasets show that DrMAD is at least 45\ntimes faster and consumes 100 times less memory compared to state-of-the-art\nmethods for optimizing hyperparameters with minimal compromise to its\neffectiveness. To the best of our knowledge, DrMAD is the first research\nattempt to make it practical to automatically tune thousands of hyperparameters\nof deep neural networks. The code can be downloaded from\nthis https URL\n"
},{
  "_id": "1601.00706",
  "title": "Weakly-supervised Disentangling with Recurrent Transformations for 3D  View Synthesis\n",
  "authors": "Jimei Yang, Scott Reed, Ming-Hsuan Yang, Honglak Lee",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " An important problem for both graphics and vision is to synthesize novel\nviews of a 3D object from a single image. This is particularly challenging due\nto the partial observability inherent in projecting a 3D object onto the image\nspace, and the ill-posedness of inferring object shape and pose. However, we\ncan train a neural network to address the problem if we restrict our attention\nto specific object categories (in our case faces and chairs) for which we can\ngather ample training data. In this paper, we propose a novel recurrent\nconvolutional encoder-decoder network that is trained end-to-end on the task of\nrendering rotated objects starting from a single image. The recurrent structure\nallows our model to capture long-term dependencies along a sequence of\ntransformations. We demonstrate the quality of its predictions for human faces\non the Multi-PIE dataset and for a dataset of 3D chair models, and also show\nits ability to disentangle latent factors of variation (e.g., identity and\npose) without using full supervision.\n"
},{
  "_id": "1510.08983",
  "title": "Highway Long Short-Term Memory RNNs for Distant Speech Recognition\n",
  "authors": "Yu Zhang, Guoguo Chen, Dong Yu, Kaisheng Yao, Sanjeev Khudanpur, James Glass",
  "subject": "Neural and Evolutionary Computing (cs.NE)",
  "annotation": " In this paper, we extend the deep long short-term memory (DLSTM) recurrent\nneural networks by introducing gated direct connections between memory cells in\nadjacent layers. These direct links, called highway connections, enable\nunimpeded information flow across different layers and thus alleviate the\ngradient vanishing problem when building deeper LSTMs. We further introduce the\nlatency-controlled bidirectional LSTMs (BLSTMs) which can exploit the whole\nhistory while keeping the latency under control. Efficient algorithms are\nproposed to train these novel networks using both frame and sequence\ndiscriminative criteria. Experiments on the AMI distant speech recognition\n(DSR) task indicate that we can train deeper LSTMs and achieve better\nimprovement from sequence training with highway LSTMs (HLSTMs). Our novel model\nobtains $43.9/47.7\\%$ WER on AMI (SDM) dev and eval sets, outperforming all\nprevious works. It beats the strong DNN and DLSTM baselines with $15.7\\%$ and\n$5.3\\%$ relative improvement respectively.\n"
},{
  "_id": "1510.08565",
  "title": "Attention with Intention for a Neural Network Conversation Model\n",
  "authors": "Kaisheng Yao, Geoffrey Zweig, Baolin Peng",
  "subject": "Neural and Evolutionary Computing (cs.NE)",
  "annotation": " In a conversation or a dialogue process, attention and intention play\nintrinsic roles. This paper proposes a neural network based approach that\nmodels the attention and intention processes. It essentially consists of three\nrecurrent networks. The encoder network is a word-level model representing\nsource side sentences. The intention network is a recurrent network that models\nthe dynamics of the intention process. The decoder network is a recurrent\nnetwork produces responses to the input from the source side. It is a language\nmodel that is dependent on the intention and has an attention mechanism to\nattend to particular source side words, when predicting a symbol in the\nresponse. The model is trained end-to-end without labeling data. Experiments\nshow that this model generates natural responses to user inputs.\n"
},{
  "_id": "1510.07526",
  "title": "Empirical Study on Deep Learning Models for Question Answering\n",
  "authors": "Yang Yu, Wei Zhang, Chung-Wei Hang, Bing Xiang, Bowen Zhou",
  "subject": "Computation and Language (cs.CL)",
  "annotation": " In this paper we explore deep learning models with memory component or\nattention mechanism for question answering task. We combine and compare three\nmodels, Neural Machine Translation, Neural Turing Machine, and Memory Networks\nfor a simulated QA data set. This paper is the first one that uses Neural\nMachine Translation and Neural Turing Machines for solving QA tasks. Our\nresults suggest that the combination of attention and memory have potential to\nsolve certain QA problem.\n"
},{
  "_id": "1510.07524",
  "title": "Time-resolved emission from bright hot pixels of an active region  observed in the EUV band with SDO/AIA and multi-stranded loop modeling\n",
  "authors": "E. Tajfirouze, F. Reale, A. Petralia, P. Testa",
  "subject": "Solar and Stellar Astrophysics (astro-ph.SR)",
  "annotation": " Evidence for small amounts of very hot plasma has been found in active\nregions and might be the indication of an impulsive heating, released at\nspatial scales smaller than the cross section of a single loop. We investigate\nthe heating and substructure of coronal loops in the core of one such active\nregion by analyzing the light curves in the smallest resolution elements of\nsolar observations in two EUV channels (94 A and 335 A) from the Atmospheric\nImaging Assembly on-board the Solar Dynamics Observatory. We model the\nevolution of a bundle of strands heated by a storm of nanoflares by means of a\nhydrodynamic 0D loop model (EBTEL). The light curves obtained from the random\ncombination of those of single strands are compared to the observed light\ncurves either in a single pixel or in a row of pixels, simultaneously in the\ntwo channels and using two independent methods: an artificial intelligent\nsystem (Probabilistic Neural Network, PNN) and a simple cross-correlation\ntechnique. We explore the space of the parameters to constrain the distribution\nof the heat pulses, their duration and their spatial size, and, as a feedback\non the data, their signatures on the light curves. From both methods the best\nagreement is obtained for a relatively large population of events (1000) with a\nshort duration (less than 1 min) and a relatively shallow distribution (power\nlaw with index 1.5) in a limited energy range (1.5 decades). The feedback on\nthe data indicates that bumps in the light curves, especially in the 94 A\nchannel, are signatures of a heating excess that occurred a few minutes before.\n"
},{
  "_id": "1510.07303",
  "title": "A Framework for Distributed Deep Learning Layer Design in Python\n",
  "authors": "Clay McLeod",
  "subject": "Machine Learning (cs.LG)",
  "annotation": " In this paper, a framework for testing Deep Neural Network (DNN) design in\nPython is presented. First, big data, machine learning (ML), and Artificial\nNeural Networks (ANNs) are discussed to familiarize the reader with the\nimportance of such a system. Next, the benefits and detriments of implementing\nsuch a system in Python are presented. Lastly, the specifics of the system are\nexplained, and some experimental results are presented to prove the\neffectiveness of the system.\n"
},{
  "_id": "1510.05708",
  "title": "First Results of $ν_e$ Appearance Analysis and Electron Neutrino  Identification at NOvA\n",
  "authors": "Jianming Bian",
  "subject": "High Energy Physics - Experiment (hep-ex)",
  "annotation": " NOvA is a long-baseline accelerator-based neutrino oscillation experiment\nthat is optimized for $\\nu_\\mu\\to\\nu_e$ measurements. It uses the upgraded NuMI\nbeam from Fermilab and measures electron-neutrino appearance and muon-neutrino\ndisappearance at its Far Detector in Ash River, Minnesota. The $\\nu_e$\nappearance analysis at NOvA aims to resolve the neutrino mass hierarchy problem\nand to constrain the CP-violating phase. The first data set of\n$2.74\\times10^{20}$ protons on target (POT) equivalent exposure taken by NOvA\nhas been analyzed. The first measurement of electron-neutrino appearance in\nNOvA provides solid evidence of $\\nu_\\mu\\to\\nu_e$ oscillation with the NuMI\nbeam line. Electron-neutrino identification is the key ingredient for the\n$\\nu_e$ appearance analysis. The electron-identification algorithm used to\nproduce the primary results presented here compares 3-D shower-energy profiles\nwith Monte Carlo prototypes to construct likelihoods for each particle\nhypothesis. Particle likelihoods, among other event-topology variables, are\nused as inputs to an Artificial Neural Network for the final electron-neutrino\nidentification. The design and implementation of this algorithm is also\npresented.\n"
},{
  "_id": "1510.04609",
  "title": "Layer-Specific Adaptive Learning Rates for Deep Networks\n",
  "authors": "Bharat Singh, Soham De, Yangmuzi Zhang, Thomas Goldstein, Gavin Taylor",
  "subject": "Computer Vision and Pattern Recognition (cs.CV)",
  "annotation": " The increasing complexity of deep learning architectures is resulting in\ntraining time requiring weeks or even months. This slow training is due in part\nto vanishing gradients, in which the gradients used by back-propagation are\nextremely large for weights connecting deep layers (layers near the output\nlayer), and extremely small for shallow layers (near the input layer); this\nresults in slow learning in the shallow layers. Additionally, it has also been\nshown that in highly non-convex problems, such as deep neural networks, there\nis a proliferation of high-error low curvature saddle points, which slows down\nlearning dramatically. In this paper, we attempt to overcome the two above\nproblems by proposing an optimization method for training deep neural networks\nwhich uses learning rates which are both specific to each layer in the network\nand adaptive to the curvature of the function, increasing the learning rate at\nlow curvature points. This enables us to speed up learning in the shallow\nlayers of the network and quickly escape high-error low curvature saddle\npoints. We test our method on standard image classification datasets such as\nMNIST, CIFAR10 and ImageNet, and demonstrate that our method increases accuracy\nas well as reduces the required training time over standard algorithms.\n"
}]